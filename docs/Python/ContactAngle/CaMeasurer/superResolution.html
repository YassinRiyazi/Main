<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>superResolution Documentation</title>
    <style>
        body { 
            font-family: Arial, sans-serif; 
            line-height: 1.6; 
            margin: 0; 
            padding: 0; 
            display: grid;
            grid-template-columns: 250px 1fr;
        }
        .sidebar {
            background: #f5f5f5;
            padding: 20px;
            height: 100vh;
            position: sticky;
            top: 0;
            overflow-y: auto;
        }
        .content {
            padding: 20px;
            max-width: 900px;
            margin: 0 auto;
        }
        h1 { color: #2c3e50; border-bottom: 2px solid #3498db; padding-bottom: 10px; }
        h2 { color: #2980b9; margin-top: 30px; }
        .function { 
            background: #f9f9f9; 
            border-left: 4px solid #3498db; 
            padding: 15px; 
            margin-bottom: 20px; 
        }
        .function-name { 
            color: #2c3e50; 
            font-weight: bold; 
            font-size: 1.2em;
            margin-bottom: 10px;
        }
        .section-title { 
            font-weight: bold; 
            color: #16a085; 
            margin-top: 15px;
        }
        code { 
            background: #eee; 
            padding: 2px 5px; 
            border-radius: 3px; 
            font-family: monospace;
        }
        pre { 
            background: #f5f5f5; 
            padding: 10px; 
            border-radius: 5px; 
            overflow-x: auto; 
        }
        ul {
            padding-left: 20px;
        }
        .language {
            font-weight: bold;
            margin-top: 10px;
        }
        a {
            color: #3498db;
            text-decoration: none;
        }
        a:hover {
            text-decoration: underline;
        }
        footer {
            margin-top: 30px;
            font-size: 0.8em;
            color: #7f8c8d;
        }

        /* Prism.js default theme styles (minified version adapted for inline use) */
        pre[class*="language-"] {
            background: #f5f2f0;
            color: #000;
            text-shadow: 0 1px #fff;
            font-family: Consolas, Monaco, 'Andale Mono', monospace;
            font-size: 1em;
            text-align: left;
            white-space: pre;
            word-spacing: normal;
            word-break: normal;
            word-wrap: normal;
            line-height: 1.5;
            tab-width: 4;
            hyphens: none;
            padding: 1em;
            margin: .5em 0;
            overflow: auto;
            border-radius: 0.3em;
        }
        code[class*="language-"] {
            background: #f5f2f0;
            color: #000;
            font-family: Consolas, Monaco, 'Andale Mono', monospace;
            font-size: 1em;
            text-align: left;
            white-space: pre;
            word-spacing: normal;
            word-break: normal;
            word-wrap: normal;
            line-height: 1.5;
            tab-width: 4;
            hyphens: none;
        }
        .token.command {
            color: #005cc5;
        }
        .token.parameter {
            color: #22863a;
        }
    </style>
</head>
<body>
    <nav class="sidebar">
<h2>Navigation</h2>
<ul>
<li class="language">Python
<ul>
<li>ContactAngle<ul>
<li>CaMeasurer<ul>
<li><a href="criteria_definition.html">criteria_definition.py</a></li>
<li><a href="edgeDetection.html">edgeDetection.py</a></li>
<li><a href="imageloader.html">imageloader.py</a></li>
<li><a href="main.html">main.py</a></li>
<li><a href="preprocessing.html">preprocessing.py</a></li>
<li><a href="processing.html">processing.py</a></li>
<li><a href="superResolution.html">superResolution.py</a></li>
<li><a href="visualization.html">visualization.py</a></li>
</ul></li>
<li><a href="../main.html">main.py</a></li>
<li>models<ul>
<li><a href="../models/edge_superres_pytorch.html">edge_superres_pytorch.py</a></li>
<li><a href="../models/h5toPt.html">h5toPt.py</a></li>
</ul></li>
</ul></li>
<li>ContinuousVideoExperiments<ul>
<li><a href="../../ContinuousVideoExperiments/contVideo.html">contVideo.py</a></li>
</ul></li>
<li>DropDetection<ul>
<li><a href="../../DropDetection/DropDetection_AbsDifference.html">DropDetection_AbsDifference.py</a></li>
<li><a href="../../DropDetection/DropDetection_Sum.html">DropDetection_Sum.py</a></li>
<li><a href="../../DropDetection/utils.html">utils.py</a></li>
</ul></li>
<li>DropLowHighUnifier<ul>
<li><a href="../../DropLowHighUnifier/BottomRowUnifier.html">BottomRowUnifier.py</a></li>
</ul></li>
<li>DynamicLoader<ul>
<li>load-remote-module<ul>
<li>load_remote_module<ul>
<li><a href="../../DynamicLoader/load-remote-module/load_remote_module/DLoader.html">DLoader.py</a></li>
</ul></li>
</ul></li>
</ul></li>
<li>FFMpeg<ul>
<li><a href="../../FFMpeg/Vidoe2Jpg.html">Vidoe2Jpg.py</a></li>
</ul></li>
<li>Performance<ul>
<li><a href="../../Performance/Performance_mesurements.html">Performance_mesurements.py</a></li>
</ul></li>
<li>Test<ul>
<li><a href="../../Test/test.html">test.py</a></li>
</ul></li>
<li><a href="../../notes.html">python_notes.md</a></li>
</ul>
</li>
<li class="language">C
<ul>
<li>Test<ul>
<li><a href="../../../C/Test/temp.html">temp.c</a></li>
</ul></li>
<li><a href="../../../C/notes.html">c_notes.md</a></li>
</ul>
</li>
<li class="language">C++
<ul>
<li><a href="../../../C++/notes.html">c++_notes.md</a></li>
</ul>
</li>
<li class="language">CUDA
<ul>
<li><a href="../../../CUDA/notes.html">cuda_notes.md</a></li>
</ul>
</li>
</ul>
</nav>
    
    <div class="content">
        <h1>superResolution Documentation</h1>
        
        <div class="function">
<div class="function-name">upscale_image(<span style="color:#94D6BFFF;"><b>img</b></span>:<span style="color:#42C39DFF;"><b>np.ndarray</b></span>, <span style="color:#94D6BFFF;"><b>kernel</b></span>:<span style="color:#42C39DFF;"><b>np.ndarray</b></span>,)</div>
<div class="description">Apply super-resolution and postprocessing to an input RGB image.</div>
<div class="section-title">Parameters:</div><ul>
<li><code>img</code> (np.ndarray): RGB input image.</li>
<li><code>kernel</code> (np.ndarray): Morphological kernel (e.g., cv2.getStructuringElement).</li>
</ul>
<div class="section-title">Returns:</div>
<div><code>np.ndarray</code>: Grayscale post-processed image.</div>
</div>
<div class="function">
<div class="function-name">__init__()</div>
<div class="description">A PyTorch convolutional neural network for single-channel image super-resolution. Architecture: - Conv2d(1 → 64) with kernel size 5 - Conv2d(64 → 64) with kernel size 3 - Conv2d(64 → 32) with kernel size 3 - Conv2d(32 → 9) with kernel size 3 - PixelShuffle with upscale factor 3 Activation: - ReLU is used after each convolution. Output: - A super-resolved image with spatial resolution increased by a factor of 3.</div>
<div class=section-title>notes:</div>
<div>- The final convolution outputs 9 channels, which are reshaped via PixelShuffle (3× upscaling).</div>
</div>
<div class="function">
<div class="function-name">__init__(<span style="color:#94D6BFFF;"><b>_cuda</b></span>:<span style="color:#42C39DFF;"><b>bool</b></span>, <span style="color:#94D6BFFF;"><b>sup_res_model</b></span>:<span style="color:#42C39DFF;"><b>torch.nn.Module</b></span>, <span style="color:#94D6BFFF;"><b>forward</b></span>:<span style="color:#42C39DFF;"><b>input_tensor</b></span>,)</div>
<div class="description">Wrapper class for initializing and using a pre-trained PyTorch super-resolution model. This class loads a pre-trained model from disk and provides a `forward` method to apply super-resolution to a single-channel input image represented as a NumPy array.</div>
<div class="section-title">Parameters:</div><ul>
<li><code>_cuda</code> (bool): Whether to run inference on GPU (default: True).</li>
<li><code>sup_res_model</code> (torch.nn.Module): The loaded and ready-to-use super-resolution model.</li>
<li><code>forward</code> (input_tensor): Apply the model to a given input image.</li>
</ul>
<div class=section-title>examples:</div>
<div>>>> model = initiation()</div>
<div>>>> output = model.forward(input_array)</div>
<div class=section-title>notes:</div>
<div>- The input tensor must be a 2D NumPy array (grayscale image).</div>
<div>- Output is a 2D uint8 NumPy array representing the upscaled image.</div>
</div>
<div class="function">
<div class="function-name">forward(<span style="color:#94D6BFFF;"><b>input_tensor</b></span>:<span style="color:#42C39DFF;"><b>np.ndarray</b></span>,)</div>
<div class="description">Apply the super-resolution model to the input image.</div>
<div class="section-title">Parameters:</div><ul>
<li><code>input_tensor</code> (np.ndarray): 2D NumPy array representing a grayscale image.</li>
</ul>
<div class="section-title">Returns:</div>
<div><code>np.ndarray</code>: 2D uint8 NumPy array of the super-resolved image.</div>
<div class=section-title>raises:</div>
<div>{'type': 'ValueError', 'desc': 'If input_tensor is not a 2D array.'}</div>
<div class=section-title>notes:</div>
<div>- The model expects a (1, H, W) input with values normalized to [0, 1].</div>
<div>- Output is rescaled to [0, 255] and clipped.</div>
</div>
<div class="function">
<div class="function-name">initiate_torch()</div>
<div class="description">Initialize the PyTorch model and load pre-trained weights from disk.</div>
<div class=section-title>notes:</div>
<div>- The model weights are loaded from '../models/converted_model.pt'</div>
<div>- The model is set to evaluation mode to disable dropout/batchnorm updates.</div>
</div>
        
        <footer>
            <p>Documentation generated on <span>2025-07-20 21:58:16</span></p>
            <p>Raw access: <span><a href="https://raw.githubusercontent.com/YassinRiyazi/Main/refs/heads/main/src/PyThon/ContactAngle/CaMeasurer/superResolution.py">https://raw.githubusercontent.com/YassinRiyazi/Main/refs/heads/main/src/PyThon/ContactAngle/CaMeasurer/superResolution.py</a></span></p>
        </footer>
    </div>
</body>
</html>