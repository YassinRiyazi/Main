"""
    https://medium.com/@gunjassingh/positional-encoding-in-transformers-a-visual-and-intuitive-guide-0761e655cea7
    https://medium.com/data-science/master-positional-encoding-part-i-63c05d90a0c3

    one of the most important concepts of a transformer model — positional encoding. 
    The authors of “Attention is all you need” chose a combination of sinusoidal curves for the positional encoding vectors.

    y: Position
    x: Embedding dimension


"""